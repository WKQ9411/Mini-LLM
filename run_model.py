# -*- coding: utf-8 -*-
import streamlit as st
import torch
from transformers import AutoTokenizer
import time
import traceback  # ç”¨äºæ›´è¯¦ç»†çš„é”™è¯¯è¿½è¸ª
import html
from model import get_model_and_args
from utils.little_tools import load_yaml
import inspect


# --- å®šä¹‰åˆ†è¯å™¨ ---
TOKENIZER_NAME = "./mini_tokenizer"

# --- æ¨¡å‹é…ç½®å®šä¹‰ï¼Œæ ¹æ®æ¨¡å‹æƒé‡å®é™…è·¯å¾„ä¿®æ”¹ ---
MODEL_CONFIG_DEFINITIONS = {
    "mini_deepseekv3": {
        "path": "C:/Users/WKQ/Downloads/sft_model/mini_deepseekv3/sft_mini_deepseekv3_final_loss_2.09-chat.pt",
        "yaml": "C:/Users/WKQ/Downloads/sft_model/mini_deepseekv3/sft_mini_deepseekv3_model_args.yaml",
        "inference_args": {"use_noaux_tc": True},  # å®šä¹‰æ¨¡å‹ç‰¹æœ‰æ¨ç†å‚æ•°
        "description": "MoE",
    },
    "mini_llama3": {
        "path": "C:/Users/WKQ/Downloads/sft_model/mini_llama3/sft_mini_llama3_final_loss_2.52-chat.pt",
        "yaml": "C:/Users/WKQ/Downloads/sft_model/mini_llama3/sft_mini_llama3_model_args.yaml",
        "inference_args": {},
        "description": "Dense",
    },
}


# --- å‡½æ•°å®šä¹‰ ---
# åŠ è½½æ¨¡å‹ç»“æ„
@st.cache_resource(show_spinner="åˆå§‹åŒ–æ¨¡å‹ç»“æ„...")
def get_cached_model_structure(model_name, config_dict):
    try:
        Model, Model_Args = get_model_and_args(model_name)
        model_args = Model_Args(**config_dict)
        model = Model(model_args)
        model.eval()
        return model, model_args
    except Exception as e: st.error(f"åˆå§‹åŒ–æ¨¡å‹ç»“æ„æ—¶å‡ºé”™ ({model_name}): {e}"); return None, None

# åŠ è½½æ¨¡å‹æƒé‡
@st.cache_resource(show_spinner="åŠ è½½æ¨¡å‹æƒé‡...")
def load_cached_weights(_model, model_path, device):
    if _model is None: 
        return None, "æ¨¡å‹ç»“æ„æœªæˆåŠŸåˆå§‹åŒ–"
    try: 
        _model.load_state_dict(torch.load(model_path, map_location=device))
        _model.to(device)
        return _model, "success"
    except FileNotFoundError: 
        return None, f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}"
    except Exception as e: 
        return None, f"åŠ è½½æƒé‡æ—¶å‡ºé”™: {str(e)}\n{traceback.format_exc()}"

# åŠ è½½åˆ†è¯å™¨
@st.cache_resource(show_spinner="åŠ è½½åˆ†è¯å™¨...")
def load_cached_tokenizer(tokenizer_name):
    try: 
        return AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True), "success"
    except Exception as e: 
        return None, f"åŠ è½½åˆ†è¯å™¨æ—¶å‡ºé”™ '{tokenizer_name}': {e}\n{traceback.format_exc()}"


# --- é¡µé¢é…ç½® ---
st.set_page_config( page_title="Mini-LLM", page_icon="./utils/Logo.svg", layout="wide", initial_sidebar_state="expanded", )

# --- è‡ªå®šä¹‰CSSæ ·å¼ ---
st.markdown(
    """
<style>
    /* å…¨å±€è®¾ç½® */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    * {
        font-family: 'Inter', sans-serif;
    }

    /* ä¸»é¢˜æ¸å˜è‰²è°ƒ */
    :root {
        --primary-gradient-start: #0a192f;
        --primary-gradient-end: #172a45;
        --accent-color: #64ffda;
        --card-bg: rgba(255, 255, 255, 0.08);
        --card-border: rgba(255, 255, 255, 0.1);
    }

    /* ä¿®å¤ç™½è‰²å¤´éƒ¨éƒ¨åˆ†ï¼Œä½¿å…¶ä¸ä¸»é¢˜åŒ¹é… */
    header {
        background: linear-gradient(135deg, var(--primary-gradient-start) 0%, var(--primary-gradient-end) 100%) !important;
        color: white !important;
    }

    /* ä¸»åº”ç”¨æ ·å¼ä¸åŒ¹é…çš„æ¸å˜ */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        background: linear-gradient(135deg, var(--primary-gradient-start) 0%, var(--primary-gradient-end) 100%);
        color: white;
        min-height: 100vh;
    }

    /* ä¾§è¾¹æ æ ·å¼ï¼ŒåŒ¹é…æ¸å˜è‰² */
    [data-testid="stSidebar"] > div:first-child {
        background: linear-gradient(170deg, var(--primary-gradient-start) 0%, var(--primary-gradient-end) 100%);
        color: white;
        padding-top: 1rem;
        box-shadow: 2px 0 20px rgba(0, 0, 0, 0.2);
    }

    [data-testid="stSidebar"] h1 {
        color: white;
        font-weight: 600;
        font-size: 1.6em;
        margin-bottom: 0.5rem;
        padding-bottom: 0.5rem;
        text-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
    }

    [data-testid="stSidebar"] .stMarkdown {
        color: white;
    }

    [data-testid="stSidebar"] hr {
        border-color: rgba(255, 255, 255, 0.2);
        margin: 15px 0;
    }

    /* ç»ç’ƒæ‹Ÿæ€å¡ç‰‡ */
    .sidebar-section-header {
        font-size: 1.1em;
        font-weight: 600;
        margin-top: 15px;
        margin-bottom: 15px;
        padding: 10px 12px;
        color: #f0f0f0;
        background: rgba(255, 255, 255, 0.1);
        backdrop-filter: blur(5px);
        -webkit-backdrop-filter: blur(5px);
        border-radius: 8px;
        border: 1px solid rgba(255, 255, 255, 0.08);
        display: flex;
        align-items: center;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    }

    .sidebar-section-header span {
        margin-right: 8px;
        font-size: 1.2em;
    }

    /* å‘å…‰æŒ‰é’®æ ·å¼ */
    [data-testid="stSidebar"] button {
        background: rgba(255, 255, 255, 0.1);
        color: white;
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 8px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.3s ease !important;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        text-transform: uppercase;
        font-size: 0.85em;
        letter-spacing: 0.5px;
        backdrop-filter: blur(5px);
        -webkit-backdrop-filter: blur(5px);
    }

    [data-testid="stSidebar"] button:hover {
        background: rgba(255, 255, 255, 0.2);
        border-color: var(--accent-color);
        box-shadow: 0 0 15px rgba(100, 255, 218, 0.6);
        transform: translateY(-1px);
    }

    /* ç»ç’ƒå¡ç‰‡æ ·å¼ */
    .info-card {
        background: rgba(255, 255, 255, 0.1);
        backdrop-filter: blur(10px);
        -webkit-backdrop-filter: blur(10px);
        border-radius: 12px;
        padding: 18px 22px;
        margin-bottom: 20px;
        border: 1px solid rgba(255, 255, 255, 0.15);
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);
        transition: transform 0.3s ease, box-shadow 0.3s ease;
        color: white;
    }
    
    /* ç”¨æˆ·æ¶ˆæ¯å®¹å™¨ */
    .message-container.user {
        display: flex;
        justify-content: flex-end;
        margin-bottom: 8px;
        margin-right: 8px;
    }
    
    /* ç”¨æˆ·æ°”æ³¡æ ·å¼ */
    .user-bubble {
        max-width: 80%;
        margin-left: auto;
    }
    
    /* ç”¨æˆ·æ°”æ³¡æ ·å¼ */
    .user-bubble {
        background: rgba(100, 255, 218, 0.15);
        border-radius: 18px 18px 4px 18px;
        padding: 12px 16px;
        max-width: 80%;
        margin-left: auto;
        border: 1px solid rgba(100, 255, 218, 0.3);
    }

    .info-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 12px 25px rgba(0, 0, 0, 0.15), 0 0 15px rgba(100, 255, 218, 0.3);
    }

    .info-card h4 {
        margin-top: 0;
        margin-bottom: 15px;
        color: white;
        font-size: 1.1em;
        font-weight: 700;
        display: flex;
        align-items: center;
        border-bottom: 2px solid rgba(255, 255, 255, 0.2);
        padding-bottom: 10px;
    }

    .info-card h4 span {
        margin-right: 10px;
        font-size: 1.2em;
        color: var(--accent-color);
    }

    .info-card p {
        margin-bottom: 10px;
        line-height: 1.7;
        color: rgba(255, 255, 255, 0.9);
        display: flex;
        align-items: center;
        font-size: 0.95em;
        padding: 3px 0;
    }

    .info-card p span {
        margin-right: 10px;
        width: 22px;
        text-align: center;
        color: var(--accent-color);
    }

    .info-card strong {
        color: white;
        margin-right: 5px;
        font-weight: 600;
    }

    /* è‡ªå®šä¹‰åŠ è½½åŠ¨ç”»æ–‡æœ¬æ ·å¼ */
    .stSpinner > div > div {
       color: var(--accent-color);
       font-weight: 500;
    }

    /* é‡æ–°å®šä¹‰èŠå¤©å¸ƒå±€ */
    .chat-container {
        display: flex;
        flex-direction: column;
        gap: 1.5rem; /* Reduced gap for better density */
        padding: 1rem;
        max-width: 100%;
    }

    /* æ¶ˆæ¯å®¹å™¨æ ·å¼ */
    .message-container {
        display: flex;
        flex-direction: column;
        max-width: 85%;
        margin-left: auto;
        margin-right: auto;
        transition: transform 0.2s ease;
    }

    .message-container.assistant {
        align-items: flex-start;
        align-self: flex-start;
        margin-left: 0;
        margin-right: auto;
        margin-bottom: 16px;
    }

    /* å¤´åƒæ ·å¼ */
    .avatar {
        width: 38px; height: 38px; border-radius: 50%; display: flex;
        align-items: center; justify-content: center; font-size: 16px;
        margin-bottom: 6px; box-shadow: 0 3px 6px rgba(0, 0, 0, 0.15);
        transition: transform 0.3s ease;
    }
    .avatar:hover { transform: scale(1.1) rotate(5deg); }
    .avatar.user { background: linear-gradient(135deg, #4338ca, #3b82f6); color: white; margin-left: auto; }
    .avatar.assistant { background: linear-gradient(135deg, #6d28d9, #8b5cf6); color: white; margin-right: auto; }

    /* èŠå¤©æ°”æ³¡æ ·å¼ - å®½åº¦é€‚é… */
    .chat-bubble {
        padding: 0.8rem 1rem; border-radius: 1rem; position: relative;
        margin-bottom: 0.3rem; animation: fadeIn 0.3s ease;
        box-shadow: 0 3px 6px rgba(0, 0, 0, 0.1);
        width: fit-content; /* --- é€‚é…å†…å®¹å®½åº¦ --- */
        max-width: 100%; word-wrap: break-word; line-height: 1.6;
    }
    .chat-bubble span { display: block; } /* å…è®¸å†…å®¹å—çº§æ˜¾ç¤ºå’Œæ¢è¡Œ */
    @keyframes fadeIn { from {opacity: 0; transform: translateY(10px);} to {opacity: 1; transform: translateY(0);} }
    .user-bubble { background: linear-gradient(135deg, #4338ca, #3b82f6); color: white; border-top-right-radius: 0.25rem; box-shadow: 0 3px 10px rgba(59, 130, 246, 0.3); }
    .assistant-bubble { 
        background: linear-gradient(135deg, #1e293b, #334155); 
        color: #f3f4f6; 
        border-top-left-radius: 0.25rem; 
        box-shadow: 0 3px 10px rgba(15, 23, 42, 0.3);
        margin-left: 0;
        transform-origin: left center;
    }

    /* æ°”æ³¡ä¿¡æ¯æ æ ·å¼ */
    .bubble-info { font-size: 0.7rem; opacity: 1; display: flex; justify-content: flex-start; gap: 10px; padding-top: 0.4rem; margin-top: 0.4rem; border-top: 1px solid rgba(255, 255, 255, 0.15); animation: fadeIn 0.3s ease forwards; }
    .bubble-info span { display: inline-flex; align-items: center; }
    .bubble-info span svg, .bubble-info span i { margin-right: 3px; font-size: 0.8em; }

    /* æ ‡é¢˜æ ·å¼ */
    .main h1 { color: #ffffff; font-weight: 800; letter-spacing: -0.5px; padding-bottom: 10px; border-bottom: 2px solid rgba(255, 255, 255, 0.2); margin-bottom: 20px; text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2); }

    /* è¯´æ˜æ–‡æœ¬æ ·å¼ */
    .main .caption-text { font-style: italic; color: rgba(255, 255, 255, 0.9); margin-bottom: 20px; padding: 12px 18px; background-color: rgba(255, 255, 255, 0.1); backdrop-filter: blur(5px); -webkit-backdrop-filter: blur(5px); border-radius: 8px; border-left: 3px solid var(--accent-color); box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1); }

    /* ç»ç’ƒæ‹Ÿæ€è®¾ç½®é¢æ¿ */
    .stExpander { border-radius: 10px; border: 1px solid rgba(255, 255, 255, 0.15); margin-top: 10px; background: rgba(255, 255, 255, 0.1); backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); overflow: hidden; }
    .stExpander > div:first-child { padding: 1rem; background: rgba(255, 255, 255, 0.1); border-radius: 10px 10px 0 0; }
    .stExpander > div:last-child { border-top: 1px solid rgba(255, 255, 255, 0.1); padding: 1rem; background: rgba(255, 255, 255, 0.05); border-radius: 0 0 10px 10px; }
    /* æ»‘å—æ§ä»¶æ ·å¼ */
    .stSlider > div > div > div { background-color: rgba(255, 255, 255, 0.2) !important; }
    .stSlider > div > div > div > div { background-color: var(--accent-color) !important; }
    /* ç§»åŠ¨è®¾å¤‡å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) { .main .block-container { padding: 1rem 0.5rem; } .message-container { max-width: 95%; } .info-card { padding: 12px 15px; } .main h1 { font-size: 1.8em; } .chat-container { gap: 1rem; } }
    /* ç°ä»£åŠ¨ç”»è¿›åº¦æ¡ */
    .progress-bar-container { width: 100%; height: 6px; background-color: rgba(255, 255, 255, 0.1); border-radius: 3px; margin: 10px 0; overflow: hidden; }
    .progress-bar { height: 100%; background: linear-gradient(90deg, var(--primary-gradient-start) 0%, var(--accent-color) 100%); background-size: 200% 100%; animation: loading-indeterminate 1.5s linear infinite; border-radius: 3px; }
    @keyframes loading-indeterminate { 0% { background-position: 200% 0; } 100% { background-position: -200% 0; } }
    /* åŠ è½½å…ƒç´ çš„è„‰å†²åŠ¨ç”» */
    @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.6; } }
    .pulse { animation: pulse 1.5s infinite; }
    /* çŠ¶æ€æç¤ºæ¡†æ ·å¼ */
    .alert-box { padding: 12px 16px; border-radius: 10px; margin: 15px 0; display: flex; align-items: center; backdrop-filter: blur(5px); -webkit-backdrop-filter: blur(5px); }
    .alert-box.error { background-color: rgba(239, 68, 68, 0.2); border-left: 4px solid #ef4444; }
    .alert-box.info { background-color: rgba(100, 255, 218, 0.15); border-left: 4px solid var(--accent-color); }
    .alert-box.warning { background-color: rgba(245, 158, 11, 0.15); border-left: 4px solid #f59e0b; }
    /* å‚æ•°æŒ‡ç¤ºå™¨æ ·å¼ */
    .param-indicator { display: flex; justify-content: space-between; font-size: 0.8em; color: rgba(255, 255, 255, 0.8); margin-bottom: 5px; }
    .param-meter { width: 100%; height: 6px; background-color: rgba(255, 255, 255, 0.1); border-radius: 3px; overflow: hidden; margin-bottom: 10px; }
    .param-meter-fill { height: 100%; background: linear-gradient(90deg, var(--primary-gradient-start) 0%, var(--accent-color) 100%); border-radius: 3px; transition: width 0.5s ease-out; }
    /* åœ¨ä¾§è¾¹æ ä¸­ä½¿é€‰æ‹©æ¡†æ ‡ç­¾ä¸ºç™½è‰² */
    [data-testid="stSidebar"] .stSelectbox label { color: white !important; font-weight: 500; margin-bottom: 8px; }
    /* éšè—åŸå§‹èŠå¤©æ§ä»¶ */
    .stChatMessage { display: none !important; }

</style>
""",
    unsafe_allow_html=True,
)

# --- åˆå§‹åŒ– Session State ---
if "messages" not in st.session_state: 
    st.session_state.messages = []
if "model_loaded" not in st.session_state: 
    st.session_state.model_loaded = False
if "current_model_name" not in st.session_state: 
    st.session_state.current_model_name = None
if "gen_params" not in st.session_state:
    st.session_state.gen_params = {
        "temperature": 0.8, 
        "top_k": 50, 
        "top_p": 0.9, 
        "repetition_penalty": 1.0, 
        "frequency_penalty": 0.5
        }
if "load_error" not in st.session_state:
    st.session_state.load_error = None


# --- ä¾§è¾¹æ  ---
with st.sidebar:
    col1, col2 = st.columns([1, 5], vertical_alignment="bottom")
    with col1:
        st.image("./utils/Logo_gray.svg", width=60)
    with col2:
        st.title("Mini-LLM æ§åˆ¶é¢æ¿")

    # 1. æ¨¡å‹é€‰æ‹©ä¸åŠ è½½
    st.markdown("---")
    st.markdown('<p class="sidebar-section-header"><span>ğŸ’¾</span>æ¨¡å‹é€‰æ‹©ä¸åŠ è½½</p>', unsafe_allow_html=True)
    model_options_display = { name: f"{name} ({config.get('description', 'æ— æè¿°')})" for name, config in MODEL_CONFIG_DEFINITIONS.items() }
    # è·å–æ¨¡å‹åç§°
    def get_model_name_from_display(display_str): 
        parts = display_str.split(" (", 1)  # å‚æ•° 1 è¡¨ç¤ºåªåˆ†å‰²ä¸€æ¬¡
        return parts[0] if parts else display_str

    current_model_idx = 0
    if st.session_state.current_model_name:
        try: 
            current_model_idx = list(MODEL_CONFIG_DEFINITIONS.keys()).index(st.session_state.current_model_name)
        except ValueError: 
            current_model_idx = 0
    selected_display_option = st.selectbox(
        "ğŸ§  é€‰æ‹©ä¸€ä¸ªæ¨¡å‹:",
        options=list(model_options_display.values()), 
        index=current_model_idx, 
        key="model_select", 
        help="ä»åˆ—è¡¨ä¸­é€‰æ‹©è¦åŠ è½½å’Œä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ã€‚"
        )
    model_option = get_model_name_from_display(selected_display_option)
    load_button_placeholder = st.empty()
    load_status_placeholder = st.empty()

    if load_button_placeholder.button(f"åŠ è½½ {model_option}", key="load_model_button", use_container_width=True, icon="ğŸš€"):
        if st.session_state.model_loaded and st.session_state.current_model_name != model_option: 
            st.session_state.messages = []
        keys_to_clear = ["model", "config", "approx_params", "model_args", "device", "tokenizer", "current_model_name", "model_loaded", "load_error"]
        if st.session_state.current_model_name != model_option: 
            get_cached_model_structure.clear()
            load_cached_weights.clear()
            load_cached_tokenizer.clear()
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
        st.session_state.model_loaded = False
        st.session_state.current_model_name = None
        loading_msg = f"æ­£åœ¨å‡†å¤‡åŠ è½½ {model_option}..."
        load_status_placeholder.markdown(f"""<div style="padding: 10px; border-radius: 8px; background-color: rgba(255,255,255,0.1); margin: 10px 0;"><div style="display: flex; align-items: center; margin-bottom: 8px;"><div style="margin-right: 10px;">â³</div><div style="font-weight: 500;">{loading_msg}</div></div><div class="progress-bar-container"><div class="progress-bar"></div></div></div>""", unsafe_allow_html=True)
        load_success = False
        load_start_time = time.time()
        try:
            selected_model_info = MODEL_CONFIG_DEFINITIONS.get(model_option)
            if not selected_model_info:
                error_msg = f"æ¨¡å‹ '{model_option}' çš„é…ç½®æœªæ‰¾åˆ°ï¼"
                st.toast(error_msg, icon="âŒ")
                st.session_state.load_error = f"é…ç½®ç¼ºå¤±: {model_option}"
            else:
                model_path = selected_model_info["path"]
                yaml_path = selected_model_info["yaml"]
                inference_args = selected_model_info.get("inference_args", {})
                config_from_yaml = load_yaml(yaml_path)

                if config_from_yaml is None:
                    raise ValueError(f"æ— æ³•ä» '{yaml_path}' åŠ è½½ YAML é…ç½®ã€‚")
                config_from_yaml["max_batch_size"] = 1
                config_from_yaml.update(inference_args)
                device = "cuda" if torch.cuda.is_available() else "cpu"
                model, model_args = get_cached_model_structure(model_option, config_from_yaml)
                if model is None:
                    raise RuntimeError("åŠ è½½æ¨¡å‹ç»“æ„å¤±è´¥ã€‚")
                loaded_model, load_weights_status = load_cached_weights(model, model_path, device)
                if load_weights_status != "success":
                    raise RuntimeError(f"åŠ è½½æƒé‡å¤±è´¥: {load_weights_status}")
                tokenizer, load_tok_status = load_cached_tokenizer(TOKENIZER_NAME);
                if load_tok_status != "success":
                    raise RuntimeError(f"åŠ è½½åˆ†è¯å™¨å¤±è´¥: {load_tok_status}")
                load_end_time = time.time()
                approx_params = "æœªçŸ¥"
                if hasattr(loaded_model, 'count_parameters'):
                    _, approx_params = loaded_model.count_parameters()
                st.session_state.update({ 
                    "model": loaded_model,
                    "config": config_from_yaml, 
                    "approx_params": approx_params, 
                    "model_args": model_args, 
                    "device": device, 
                    "tokenizer": tokenizer, 
                    "model_loaded": True, 
                    "current_model_name": model_option, 
                    "load_error": None })
                load_duration = load_end_time - load_start_time
                st.toast(f"æ¨¡å‹ '{model_option}' åŠ è½½æˆåŠŸ! ({load_duration:.2f}s)", icon="âœ…")
                load_success = True
        except FileNotFoundError as e:
            error_msg = f"æ–‡ä»¶åŠ è½½å¤±è´¥: {e}"; st.toast(error_msg, icon="âŒ")
            st.session_state.load_error = error_msg
            st.session_state.model_loaded = False
        except (Exception, RuntimeError, ValueError) as e:
            error_msg = f"åŠ è½½å¤±è´¥: {e}"
            st.toast(error_msg, icon="âŒ")
            st.session_state.load_error = error_msg
            st.session_state.model_loaded = False
            print(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {traceback.format_exc()}")
        finally:
            load_status_placeholder.empty()
            if load_success:
                st.rerun()
            elif st.session_state.load_error:
                load_status_placeholder.markdown(f"""<div class="alert-box error pulse"><div style="margin-right: 10px;">ğŸ’”</div><div style="font-weight: 500;">åŠ è½½å¤±è´¥: {st.session_state.load_error}</div></div>""", unsafe_allow_html=True)
            if not load_success:
                 if load_button_placeholder.button(f"ğŸ”„ é‡è¯•åŠ è½½ {model_option}", key="reload_model_button_after_fail", use_container_width=True): st.rerun()
    
    # 2. æ¨¡å‹ä¿¡æ¯
    st.markdown("---")
    st.markdown('<p class="sidebar-section-header"><span>â„¹ï¸</span>å½“å‰æ¨¡å‹ä¿¡æ¯</p>', unsafe_allow_html=True)
    if st.session_state.get("model_loaded", False) and st.session_state.get("current_model_name"):
        display_name = st.session_state.current_model_name
        display_params = st.session_state.get("approx_params", "N/A")
        display_len = st.session_state.config.get("max_seq_len", "N/A") if "config" in st.session_state and st.session_state.config else "N/A"
        display_device = st.session_state.get("device", "N/A").upper()
        tok_vocab_size = st.session_state.tokenizer.vocab_size if st.session_state.get("tokenizer") and hasattr(st.session_state.tokenizer, 'vocab_size') else "N/A"
        st.markdown(f"""<div class="info-card"><h4><span>ğŸ§©</span>æ¨¡å‹è¯¦æƒ…</h4><p><span>ğŸ·ï¸</span><strong>åç§°:</strong> {display_name}</p><p><span>âš™ï¸</span><strong>å‚æ•° (çº¦):</strong> {display_params}</p><p><span>â†”ï¸</span><strong>æœ€å¤§é•¿åº¦:</strong> {display_len} tokens</p><p><span>ğŸ—£ï¸</span><strong>è¯æ±‡é‡:</strong> {tok_vocab_size}</p><p><span>ğŸ’»</span><strong>è¿è¡Œè®¾å¤‡:</strong> {display_device}</p></div>""", unsafe_allow_html=True)
    elif st.session_state.get("load_error"):
        st.markdown(f"""<div class="alert-box error"><div style="margin-right: 10px;">âš ï¸</div><div style="font-weight: 500;">æ¨¡å‹æœªåŠ è½½ã€‚ä¸Šæ¬¡é”™è¯¯: {st.session_state.load_error}</div></div>""", unsafe_allow_html=True)
    else:
        st.markdown(f"""<div class="alert-box info"><div style="margin-right: 10px;">ğŸ‘†</div><div style="font-weight: 500;">è¯·åœ¨ä¸Šæ–¹é€‰æ‹©æ¨¡å‹å¹¶ç‚¹å‡» 'åŠ è½½æ¨¡å‹'ã€‚</div></div>""", unsafe_allow_html=True)
    
    # 3. ç”Ÿæˆå‚æ•°
    st.markdown("---")
    st.markdown('<p class="sidebar-section-header"><span>ğŸ”§</span>ç”Ÿæˆå‚æ•°è°ƒæ•´</p>', unsafe_allow_html=True)
    model_loaded = st.session_state.get("model_loaded", False)
    with st.expander("å±•å¼€è°ƒæ•´ç”Ÿæˆå‚æ•°", expanded=False):
        gen_params = st.session_state.gen_params
        temp = st.slider("ğŸŒ¡ï¸ Temperature (éšæœºæ€§)", 0.01, 2.0, gen_params.get('temperature', 0.8), 0.01, help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚è¾ƒä½å€¼æ›´ç²¾ç¡®ï¼Œè¾ƒé«˜å€¼æ›´å…·åˆ›æ„ã€‚", key="param_temp", disabled=not model_loaded)
        temp_text_color = "#a0aec0"; temp_label = "å¹³è¡¡";
        if temp < 0.5: 
            temp_label = "æ›´ç²¾ç¡®"
            temp_text_color = "#63b3ed"
        elif temp > 1.2:
            temp_label = "æ›´åˆ›æ„"
            temp_text_color = "#fc8181"
        st.markdown(f"""<div class="param-indicator"><span>0.01</span><span style="font-weight: 600; color: {temp_text_color};">{temp_label} ({temp:.2f})</span><span>2.00</span></div>""", unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            top_k = st.slider("ğŸ” Top-k (æœ€ä½³tokenæ•°)", 1, 200, gen_params.get('top_k', 50), 1, help="åœ¨æ¯æ­¥ç”Ÿæˆæ—¶ï¼Œä»…è€ƒè™‘æ¦‚ç‡æœ€é«˜çš„ k ä¸ªtokenã€‚", key="param_topk", disabled=not model_loaded)
        with col2:
            top_p = st.slider("ğŸ…¿ï¸ Top-p (æ ¸é‡‡æ ·)", 0.1, 1.0, gen_params.get('top_p', 0.9), 0.01, help="é€‰æ‹©ç´¯ç§¯æ¦‚ç‡è¶…è¿‡ p çš„æœ€å°tokené›†è¿›è¡Œé‡‡æ · (0.1 åˆ° 1.0)ã€‚", key="param_topp", disabled=not model_loaded)
        col3, col4 = st.columns(2)
        with col3:
            rep_pen = st.slider("ğŸ” é‡å¤æƒ©ç½š", 1.0, 2.0, gen_params.get('repetition_penalty', 1.0), 0.01, help="å¯¹é‡å¤å‡ºç°çš„tokenæ–½åŠ æƒ©ç½š (å¤§äº 1.0 ä¼šå‡å°‘é‡å¤ï¼Œä¸å¯ä¸é¢‘ç‡æƒ©ç½šåŒæ—¶ä½¿ç”¨)ã€‚", key="param_reppen", disabled=not model_loaded)
        with col4:
            freq_pen = st.slider("ğŸ”„ é¢‘ç‡æƒ©ç½š", 0.0, 2.0, gen_params.get('frequency_penalty', 0.5), 0.01, help="åŸºäºtokenåœ¨å·²ç”Ÿæˆæ–‡æœ¬ä¸­çš„é¢‘ç‡é™ä½å…¶æ¦‚ç‡ (0 è¡¨ç¤ºä¸æƒ©ç½šï¼Œä¸å¯ä¸é‡å¤æƒ©ç½šåŒæ—¶ä½¿ç”¨)ã€‚", key="param_freqpen", disabled=not model_loaded)
        if model_loaded:
            creativity_score = max(0, min(1.0, (temp / 2.0 * 0.5) + (top_p * 0.3) + ((200 - top_k) / 200 * 0.2)))
            coherence_score = max(0, min(1.0, ((2.0 - temp) / 2.0 * 0.4 if temp > 0 else 0.4) + ((2.0 - (rep_pen - 1.0)) * 0.3) + ((2.0 - freq_pen)/ 2.0 * 0.3)))
            st.markdown("""<div style="background-color: rgba(255, 255, 255, 0.05); border-radius: 8px; padding: 10px 12px; margin-top: 15px; border: 1px solid rgba(255,255,255,0.1);"><div style="font-weight: 600; font-size: 0.9em; margin-bottom: 10px; color: white; text-align: center;">å‚æ•°ç»„åˆå€¾å‘ (ä¼°ç®—)</div>""", unsafe_allow_html=True)
            st.markdown(f"""<div style="margin-bottom: 8px;"><div class="param-indicator"><span>åˆ›é€ æ€§</span><span>{creativity_score:.2f} / 1.0</span></div><div class="param-meter"><div class="param-meter-fill" style="width: {creativity_score*100}%; background: linear-gradient(90deg, #8b5cf6 0%, #ec4899 100%);"></div></div></div>""", unsafe_allow_html=True)
            st.markdown(f"""<div><div class="param-indicator"><span>ç²¾ç¡®æ€§/è¿è´¯æ€§</span><span>{coherence_score:.2f} / 1.0</span></div><div class="param-meter"><div class="param-meter-fill" style="width: {coherence_score*100}%; background: linear-gradient(90deg, #22d3ee 0%, #6ee7b7 100%);"></div></div></div></div>""", unsafe_allow_html=True)
        st.session_state.gen_params = { "temperature": temp, "top_k": top_k, "top_p": top_p, "repetition_penalty": rep_pen, "frequency_penalty": freq_pen }
    if not model_loaded:
        st.markdown("""<div class="alert-box warning" style="margin-top: 10px;"><div style="margin-right: 10px;">ğŸ”’</div><div style="font-weight: 500;">åŠ è½½æ¨¡å‹åå¯è°ƒæ•´ç”Ÿæˆå‚æ•°ã€‚</div></div>""", unsafe_allow_html=True)
    
    # 4. å¯¹è¯æ§åˆ¶
    st.markdown("---")
    st.markdown('<p class="sidebar-section-header"><span>âš™ï¸</span>å¯¹è¯æ§åˆ¶</p>', unsafe_allow_html=True)
    if st.button("æ¸…ç©ºå¯¹è¯å†å²", key="clear_chat", use_container_width=True, disabled=not st.session_state.messages, icon="ğŸ§¹"):
        st.session_state.messages = []
        st.toast("å¯¹è¯å†å²å·²æ¸…ç©º", icon="ğŸ§¹")
        st.rerun()


# --- å¯¹è¯ç•Œé¢ ---
col1, col2 = st.columns([1, 10], vertical_alignment="bottom")
with col1:
    st.image("./utils/logo_gray.svg", width=60)
with col2:
    st.title("Mini-LLM")

# --- å±•ç¤ºçŠ¶æ€ ---
if st.session_state.get("model_loaded", False) and st.session_state.get("current_model_name"):
    temp_value = st.session_state.gen_params.get('temperature', 'N/A')
    temp_display = f"{temp_value:.2f}" if isinstance(temp_value, (float, int)) else temp_value
    st.markdown(f"""<div class="caption-text"><span style="font-weight: 600;">ğŸ’¡ å½“å‰æ¨¡å‹:</span> {st.session_state.current_model_name} | <span style="font-weight: 600;">ğŸŒ¡ï¸ æ¸©åº¦:</span> {temp_display} | <span style="font-weight: 600;">ğŸ’» è¿è¡Œè®¾å¤‡:</span> {st.session_state.get("device", "N/A").upper()}</div>""", unsafe_allow_html=True)
elif st.session_state.get("load_error"):
    st.markdown(f"""<div class="caption-text" style="border-left-color: #ef4444; color: #fecaca;"><span style="font-weight: 600;">ğŸš« æ¨¡å‹åŠ è½½å‡ºé”™:</span> {st.session_state.load_error}</div>""", unsafe_allow_html=True)
else:
    st.markdown("""<div class="caption-text" style="border-left-color: #f59e0b; color: #fed7aa;"><span style="font-weight: 600;">âš ï¸ å½“å‰æ— æ¨¡å‹åŠ è½½ï¼Œè¯·åœ¨ä¾§è¾¹æ åŠ è½½æ¨¡å‹ã€‚</span></div>""", unsafe_allow_html=True)


# --- å¯¹è¯å†å²å±•ç¤º ---
chat_display_container = st.container()
with chat_display_container:
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for i, message in enumerate(st.session_state.messages):
        role = message["role"]
        content = message["content"]
        
        if role == "user":
            escaped_content = html.escape(content)
            st.markdown(f"""<div class="message-container user"><div class="avatar user">ğŸ‘¤</div><div class="chat-bubble user-bubble"><span>{escaped_content}</span></div></div>""", unsafe_allow_html=True)
        elif role == "assistant":
            bubble_info_html = ""
            escaped_content = html.escape(content)
            st.markdown(f"""<div class="message-container assistant"><div class="avatar assistant">ğŸ¤–</div><div class="chat-bubble assistant-bubble"><span>{escaped_content}</span>{bubble_info_html}</div></div>""", unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)


# --- å¤„ç†å¯¹è¯è¾“å…¥è¾“å‡º ---
prompt = st.chat_input( "ğŸ’¬ è¯·åœ¨æ­¤è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤...", disabled=not st.session_state.get("model_loaded", False), key="chat_input" )

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    escaped_content = html.escape(prompt)
    st.markdown(f"""<div class="message-container user"><div class="avatar user">ğŸ‘¤</div><div class="chat-bubble user-bubble"><span>{escaped_content}</span></div></div>""", unsafe_allow_html=True)
    streaming_placeholder = st.empty()

    try:
        # --- è·å–å¿…è¦çš„çŠ¶æ€å’Œé…ç½® ---
        gen_params = st.session_state.gen_params
        model = st.session_state.model
        tokenizer = st.session_state.tokenizer
        config = st.session_state.config
        device = st.session_state.device
        max_len = config.get("max_seq_len", 512) if config else 512

        # --- å‡†å¤‡ generate å‡½æ•°çš„å‚æ•° ---
        generate_args = {
            "prompt": prompt,
            "context_length": max_len,
            "tokenizer": tokenizer,
            "stream": True,
            "task": "chat",
            "temperature": gen_params.get("temperature", 0.8),
            "top_k": gen_params.get("top_k", 50),
            "top_p": gen_params.get("top_p", 0.9),
            "repetition_penalty": gen_params.get("repetition_penalty", 1.0),
            "frequency_penalty": gen_params.get("frequency_penalty", 0.5),
        }
    
        try:
            sig = inspect.signature(model.generate)
            valid_args = {k: v for k, v in generate_args.items() if k in sig.parameters}
        except AttributeError:
             print("DEBUG: Could not inspect model.generate signature, using all args.")
             valid_args = generate_args

        response_gen_start_time = time.time()
        full_response = ""

        # --- æµå¼è¾“å‡º ---
        output_generator = model.generate(**valid_args)

        # --- æµå¼è¾“å‡ºä¼˜åŒ– ---
        response_container = st.empty()
        full_response = ""
        
        # --- å¾ªç¯æ›´æ–° placeholder ---
        for chunk in output_generator:
            full_response += str(chunk)
            escaped_response = html.escape(full_response)
            
            # ä½¿ç”¨å¢é‡æ›´æ–°æ–¹å¼ï¼Œé¿å…å®Œå…¨é‡ç»˜
            response_container.markdown(f"""
            <div class="chat-container" style="gap: 0;">
                <div class="message-container assistant">
                    <div class="avatar assistant">ğŸ¤–</div>
                    <div class="chat-bubble assistant-bubble">
                        <span>{escaped_response}</span>
                        <div class="cursor-blink"></div>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # æ·»åŠ å¾®å°å»¶è¿Ÿï¼Œå¹³è¡¡æµç•…æ€§å’Œæ€§èƒ½
            time.sleep(0.01)
            
        # æœ€ç»ˆæ›´æ–°çŠ¶æ€ï¼Œé¿å…é¢‘ç¹rerun
        st.session_state.messages.append({"role": "assistant", "content": full_response})

    except Exception as e:
        error_message = f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {str(e)}"; detailed_error = traceback.format_exc()
        st.error(error_message); print(f"Generation Error: {detailed_error}")
        try:
            streaming_placeholder.empty()
        except:
            pass
        st.rerun()


# --- æœªåŠ è½½æ¨¡å‹æ—¶æ˜¾ç¤ºæç¤ºä¿¡æ¯ ---
if not prompt and not st.session_state.get("model_loaded", False) and not st.session_state.get("load_error"):
    st.markdown("""<div class="info-card" style="text-align: center; padding: 2rem; margin-top: 2rem;"><h2>ğŸ‘ˆ è¯·ä»ä¾§è¾¹æ é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹</h2><p>é€‰æ‹©ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹å¹¶ç‚¹å‡» "åŠ è½½æ¨¡å‹" æŒ‰é’®æ¥å¼€å§‹å¯¹è¯å§ï¼</p></div>""", unsafe_allow_html=True)